{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968445d5-4111-4dc4-8d4e-3a6634ce57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fosforml \n",
    "!pip install fosforio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a2c893-0340-4c08-abe6-706b98e6b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "#import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ba9ab2-e4b9-489c-a0c9-fad3680d7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b653b1f-841a-4e95-a76f-ed4b3b3991c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'EMPLOYEE_DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55cc1456-d443-4e18-808e-2aeddd42c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = my_session.sql(\"select * from {}\".format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a885559-f81a-4838-a724-f42ec89ecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756b340e-c920-44b2-88e0-136e77833d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRTH_YEAR                             0\n",
      "AGE                                    0\n",
      "QUALIFICATION                          0\n",
      "ETHNICITY                              0\n",
      "MARITAL_STATUS                         0\n",
      "GENDER                                 0\n",
      "CONTINENT                              0\n",
      "COUNTRY                                0\n",
      "STATE                                  0\n",
      "CITY                                   0\n",
      "LATITUDE                               0\n",
      "LONGITUDE                              0\n",
      "EMPLOYEE_ID                            0\n",
      "DISTANCE                               0\n",
      "ROLE                                   0\n",
      "LINE_OF_BUSINESS                       0\n",
      "DELIVERY_UNIT                          0\n",
      "PRACTICE_UNIT                          0\n",
      "EMPLOYMENT_TYPE                        0\n",
      "TURNOVER_REASONS                       0\n",
      "SHIFT                                  0\n",
      "SALARY_INR                             0\n",
      "SALARY_RANGE                           0\n",
      "SALARY_LEVELS                          0\n",
      "JOB_SATISFACTION                       0\n",
      "AVERAGE_PERCENTAGE_SALARY_HIKE         0\n",
      "AVERAGE_PERFORMANCE_RATING             0\n",
      "OVER_TIME                              0\n",
      "OVERTIME_HOURS                         0\n",
      "JOB_STARTDATE                          0\n",
      "JOB_ENDDATE                       149539\n",
      "CHURN                                  0\n",
      "TENURE_MONTHS                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d28577-8d4a-4718-bdac-0a1c4f7493e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00400020-6773-43b7-bfa4-87b11197d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIRTH_YEAR                        0\n",
      "AGE                               0\n",
      "QUALIFICATION                     0\n",
      "ETHNICITY                         0\n",
      "MARITAL_STATUS                    0\n",
      "GENDER                            0\n",
      "CONTINENT                         0\n",
      "COUNTRY                           0\n",
      "STATE                             0\n",
      "CITY                              0\n",
      "LATITUDE                          0\n",
      "LONGITUDE                         0\n",
      "EMPLOYEE_ID                       0\n",
      "DISTANCE                          0\n",
      "ROLE                              0\n",
      "LINE_OF_BUSINESS                  0\n",
      "DELIVERY_UNIT                     0\n",
      "PRACTICE_UNIT                     0\n",
      "EMPLOYMENT_TYPE                   0\n",
      "TURNOVER_REASONS                  0\n",
      "SHIFT                             0\n",
      "SALARY_INR                        0\n",
      "SALARY_RANGE                      0\n",
      "SALARY_LEVELS                     0\n",
      "JOB_SATISFACTION                  0\n",
      "AVERAGE_PERCENTAGE_SALARY_HIKE    0\n",
      "AVERAGE_PERFORMANCE_RATING        0\n",
      "OVER_TIME                         0\n",
      "OVERTIME_HOURS                    0\n",
      "JOB_STARTDATE                     0\n",
      "JOB_ENDDATE                       0\n",
      "CHURN                             0\n",
      "TENURE_MONTHS                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Original_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdeb1df6-79de-42ab-8145-ceda46243789",
   "metadata": {},
   "outputs": [],
   "source": [
    "Employee_df = Original_df.drop([\"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\",\"AVERAGE_PERCENTAGE_SALARY_HIKE\",\"AVERAGE_PERFORMANCE_RATING\",\"SALARY_RANGE\",\"LATITUDE\",\"LONGITUDE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b9a82e8-d747-463b-a8ef-13e922ddef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"QUALIFICATION\",\"ETHNICITY\",\"MARITAL_STATUS\",\"GENDER\",\"CONTINENT\",\"COUNTRY\",\"STATE\",\"CITY\",\"ROLE\",\"LINE_OF_BUSINESS\",\"DELIVERY_UNIT\",\n",
    "                      \"PRACTICE_UNIT\",\"EMPLOYMENT_TYPE\",\"TURNOVER_REASONS\",\"SHIFT\",\"SALARY_LEVELS\",\"JOB_SATISFACTION\",\"OVER_TIME\",\"DISTANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"BIRTH_YEAR\",\"AGE\",\"SALARY_INR\",\"OVERTIME_HOURS\",\"TENURE_MONTHS\"]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "DROPPED_COLUMNS = [\"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\",\"AVERAGE_PERCENTAGE_SALARY_HIKE\",\"AVERAGE_PERFORMANCE_RATING\",\"SALARY_RANGE\",\"LATITUDE\",\"LONGITUDE\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e37080-091d-4a0e-88d2-f50cf3960999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter feature columns\n",
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS\n",
    "feature_columns = [col for col in feature_columns if col in Original_df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in Original_df.columns]\n",
    " \n",
    "# Split data into features and labels\n",
    "X = Original_df[feature_columns + DROPPED_COLUMNS]\n",
    "y = Original_df[LABEL_COLUMNS].values.ravel()  # Flatten to 1D array for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdce310b-84c9-49bf-969a-965d5b5af3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52c96bdb-00f7-4d1d-9a6c-fdb6c055a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30093 entries, 288607 to 244352\n",
      "Data columns (total 32 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   QUALIFICATION                   30093 non-null  object \n",
      " 1   ETHNICITY                       30093 non-null  object \n",
      " 2   MARITAL_STATUS                  30093 non-null  object \n",
      " 3   GENDER                          30093 non-null  object \n",
      " 4   CONTINENT                       30093 non-null  object \n",
      " 5   COUNTRY                         30093 non-null  object \n",
      " 6   STATE                           30093 non-null  object \n",
      " 7   CITY                            30093 non-null  object \n",
      " 8   ROLE                            30093 non-null  object \n",
      " 9   LINE_OF_BUSINESS                30093 non-null  object \n",
      " 10  DELIVERY_UNIT                   30093 non-null  object \n",
      " 11  PRACTICE_UNIT                   30093 non-null  object \n",
      " 12  EMPLOYMENT_TYPE                 30093 non-null  object \n",
      " 13  TURNOVER_REASONS                30093 non-null  object \n",
      " 14  SHIFT                           30093 non-null  object \n",
      " 15  SALARY_LEVELS                   30093 non-null  object \n",
      " 16  JOB_SATISFACTION                30093 non-null  object \n",
      " 17  OVER_TIME                       30093 non-null  object \n",
      " 18  DISTANCE                        30093 non-null  object \n",
      " 19  BIRTH_YEAR                      30093 non-null  int16  \n",
      " 20  AGE                             30093 non-null  int8   \n",
      " 21  SALARY_INR                      30093 non-null  float64\n",
      " 22  OVERTIME_HOURS                  30093 non-null  int8   \n",
      " 23  TENURE_MONTHS                   30093 non-null  int16  \n",
      " 24  EMPLOYEE_ID                     30093 non-null  object \n",
      " 25  JOB_STARTDATE                   30093 non-null  object \n",
      " 26  JOB_ENDDATE                     30093 non-null  object \n",
      " 27  AVERAGE_PERCENTAGE_SALARY_HIKE  30093 non-null  int8   \n",
      " 28  AVERAGE_PERFORMANCE_RATING      30093 non-null  int8   \n",
      " 29  SALARY_RANGE                    30093 non-null  object \n",
      " 30  LATITUDE                        30093 non-null  object \n",
      " 31  LONGITUDE                       30093 non-null  object \n",
      "dtypes: float64(1), int16(2), int8(4), object(25)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5320d1-cc91-4f01-b127-d4b60da6806a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create pipeline\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     29\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     30\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier())\n\u001b[1;32m     31\u001b[0m ])\n\u001b[0;32m---> 33\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m result \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1439\u001b[0m ):\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1443\u001b[0m     )\n\u001b[1;32m   1445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    " \n",
    "# Define transformers\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    " \n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    " \n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aaac4-3956-443c-ab06-2ffb505e8f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968445d5-4111-4dc4-8d4e-3a6634ce57c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting fosforml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2e/3613fd0ccdbf3709dec86f87fe7624737a6f08bd1a813c88e65e7352dfde/fosforml-1.1.8-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scikit-learn==1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/89/dce01a35d354159dcc901e3c7e7eb3fe98de5cb3639c6cd39518d8830caa/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9MB 40.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-ml-python==1.5.0; python_version <= \"3.9\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/c0fa5a9bc811a59a5a1c7113ff89676ed1629d7d6463db8c1a8c97a8b5f6/snowflake_ml_python-1.5.0-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 79.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==2.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (3.5.0)\n",
      "Collecting retrying<2,>=1.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl\n",
      "Collecting snowflake-snowpark-python!=1.12.0,<2,>=1.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/1e/c78cf80cc17dfe32bd89d8c5b7d86982571d58b4d8399bfecb8296e60bf1/snowflake_snowpark_python-1.22.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 91.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catboost<1.3,>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/4a/8ada4fb635601943805cbeeb288f70982fefe48a7cef63352e318435aa98/catboost-1.2.7-cp39-cp39-manylinux2014_x86_64.whl (98.7MB)\n",
      "\u001b[K     |████████████████████████████████| 98.7MB 157kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting xgboost<2,>=1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3MB)\n",
      "\u001b[K     |████████████████████████████████| 200.3MB 107kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting anyio<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 24.6MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.2.0)\n",
      "Collecting importlib-resources<7,>=6.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl\n",
      "Collecting sqlparse<1,>=0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/a5/b2860373aa8de1e626b2bdfdd6df4355f0565b47e51f7d0c54fe70faf8fe/sqlparse-0.5.1-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 20.7MB/s eta 0:00:01\n"
     ]
    }
   ],
   "source": [
    "!pip install --q imbalanced-learn\n",
    "!pip install fosforml \n",
    "!pip install fosforio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a2c893-0340-4c08-abe6-706b98e6b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1042/3217712060.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Modeling Training and Tunning\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Statitics and Basic data support\n",
    "from scipy.stats.mstats import winsorize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling Training and Tunning\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,precision_score, recall_score, f1_score,log_loss, roc_auc_score,roc_curve, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imbalance Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Addititional\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "# Fosforml\n",
    "from fosforml import register_model\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba9ab2-e4b9-489c-a0c9-fad3680d7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b653b1f-841a-4e95-a76f-ed4b3b3991c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'EMPLOYEE_DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc1456-d443-4e18-808e-2aeddd42c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = my_session.sql(\"select * from {}\".format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a885559-f81a-4838-a724-f42ec89ecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b340e-c920-44b2-88e0-136e77833d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00400020-6773-43b7-bfa4-87b11197d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb1df6-79de-42ab-8145-ceda46243789",
   "metadata": {},
   "outputs": [],
   "source": [
    "Employee_df = Original_df.drop([\"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\",\"AVERAGE_PERCENTAGE_SALARY_HIKE\",\"AVERAGE_PERFORMANCE_RATING\",\"SALARY_RANGE\",\"LATITUDE\",\"LONGITUDE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a82e8-d747-463b-a8ef-13e922ddef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"QUALIFICATION\",\"ETHNICITY\",\"MARITAL_STATUS\",\"GENDER\",\"CONTINENT\",\"COUNTRY\",\"STATE\",\"CITY\",\"ROLE\",\"LINE_OF_BUSINESS\",\"DELIVERY_UNIT\",\n",
    "                      \"PRACTICE_UNIT\",\"EMPLOYMENT_TYPE\",\"TURNOVER_REASONS\",\"SHIFT\",\"SALARY_LEVELS\",\"JOB_SATISFACTION\",\"OVER_TIME\",\"DISTANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"BIRTH_YEAR\",\"AGE\",\"SALARY_INR\",\"OVERTIME_HOURS\",\"TENURE_MONTHS\"]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "DROPPED_COLUMNS = [\"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\",\"AVERAGE_PERCENTAGE_SALARY_HIKE\",\"AVERAGE_PERFORMANCE_RATING\",\"SALARY_RANGE\",\"LATITUDE\",\"LONGITUDE\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e37080-091d-4a0e-88d2-f50cf3960999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter feature columns\n",
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS\n",
    "feature_columns = [col for col in feature_columns if col in Original_df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in Original_df.columns]\n",
    " \n",
    "# Split data into features and labels\n",
    "X = Original_df[feature_columns + DROPPED_COLUMNS]\n",
    "y = Original_df[LABEL_COLUMNS].values.ravel()  # Flatten to 1D array for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce310b-84c9-49bf-969a-965d5b5af3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c96bdb-00f7-4d1d-9a6c-fdb6c055a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5320d1-cc91-4f01-b127-d4b60da6806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    " \n",
    "# Define transformers\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    " \n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    " \n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aaac4-3956-443c-ab06-2ffb505e8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2173e10-e301-41df-a598-c7ac64c938cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d876a-9140-41bf-9534-0bdd390f3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, log_loss, roc_auc_score\n",
    " \n",
    "# Check lengths\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "print(\"Length of y_pred:\", len(y_pred))\n",
    " \n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = sum(y_test == y_pred) / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "# Calculate additional metrics\n",
    "log_loss_value = log_loss(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob[:, 1])  # Assuming class 1 is the positive class\n",
    " \n",
    "print(\"Log Loss:\", log_loss_value)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb245d-a1ad-4338-b9ed-0c15a75d899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd2e82-5fef-4564-9cc9-6ff00a1b6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.predict(X_test)\n",
    "result_prob = pipeline.predict_proba(X_test)\n",
    "pred_df = X_test.copy()\n",
    "result = result\n",
    "result_prob = result_prob\n",
    "pred_df[\"PREDICTION\"] = result\n",
    "pred_df[\"PROB\"] = result_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc952f5-fd67-48a6-a032-dd2da67d082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, pred_df[\"PROB\"])\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred_df[\"PROB\"])\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Radnomforest')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba6e82-f1eb-4f7c-a6d4-6f33d97e2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, pred_df[\"PROB\"])\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Randomforest')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60841736-8bdc-44b1-aae6-1a29115c67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Not Churn','Churn'],\n",
    "            yticklabels=['Not CHurn','Churn'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a2164-2dc4-489d-a2b6-9c59311a84f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
